#!/usr/bin/env python3
"""
ShopTalk-AI å¿«é€ŸåŠŸèƒ½æµ‹è¯•
æµ‹è¯•RAGFlowã€Langflowå’ŒLangChainçš„åä½œ
"""

import os
import sys
import asyncio
import logging
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_imports():
    """æµ‹è¯•æ ¸å¿ƒæ¨¡å—å¯¼å…¥"""
    try:
        # æµ‹è¯•æ™ºèƒ½ä½“å¯¼å…¥
        from agents.chat_agent import ChatAgent
        from agents.knowledge_agent import KnowledgeAgent
        from agents.sentiment_agent import SentimentAgent
        logger.info("âœ… æ™ºèƒ½ä½“æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•LangChainå¯¼å…¥
        try:
            from langchain_community.chat_models import ChatOpenAI
            logger.info("âœ… LangChainç¤¾åŒºç‰ˆå¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            logger.warning(f"âš ï¸ LangChainå¯¼å…¥è­¦å‘Š: {e}")
        
        return True
    except Exception as e:
        logger.error(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_config_loading():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    try:
        import yaml
        
        # æµ‹è¯•ä¸»é…ç½®æ–‡ä»¶
        if os.path.exists('configs/configs.yaml'):
            with open('configs/configs.yaml', 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info("âœ… ä¸»é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            
            # æ£€æŸ¥å…³é”®é…ç½®
            required_sections = ['llm', 'embedding', 'redis', 'postgresql']
            for section in required_sections:
                if section in config:
                    logger.info(f"  âœ“ {section}é…ç½®å­˜åœ¨")
                else:
                    logger.warning(f"  âš ï¸ {section}é…ç½®ç¼ºå¤±")
        
        # æµ‹è¯•ç¯å¢ƒé…ç½®
        if os.path.exists('config.env'):
            logger.info("âœ… ç¯å¢ƒé…ç½®æ–‡ä»¶å­˜åœ¨")
        
        return True
    except Exception as e:
        logger.error(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False

async def test_agent_creation():
    """æµ‹è¯•æ™ºèƒ½ä½“åˆ›å»º"""
    try:
        # æ¨¡æ‹Ÿé…ç½®
        test_config = {
            'llm': {
                'model': 'gpt-3.5-turbo',
                'temperature': 0.7,
                'max_tokens': 1000
            },
            'langflow': {
                'endpoint': 'http://localhost:7860',
                'api_key': 'test_key',
                'flow_id': 'test_flow'
            }
        }
        
        # åˆ›å»ºæ™ºèƒ½ä½“
        from agents.chat_agent import ChatAgent
        chat_agent = ChatAgent(test_config)
        logger.info("âœ… ChatAgentåˆ›å»ºæˆåŠŸ")
        
        from agents.sentiment_agent import SentimentAgent
        sentiment_agent = SentimentAgent(test_config)
        logger.info("âœ… SentimentAgentåˆ›å»ºæˆåŠŸ")
        
        from agents.knowledge_agent import KnowledgeAgent
        knowledge_agent = KnowledgeAgent(test_config)
        logger.info("âœ… KnowledgeAgentåˆ›å»ºæˆåŠŸ")
        
        return True
    except Exception as e:
        logger.error(f"âŒ æ™ºèƒ½ä½“åˆ›å»ºå¤±è´¥: {e}")
        return False

async def test_mock_conversation():
    """æµ‹è¯•æ¨¡æ‹Ÿå¯¹è¯æµç¨‹"""
    try:
        # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
        test_input = {
            'user_id': 'test_user_123',
            'message': 'ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹ä½ ä»¬çš„äº§å“',
            'session_id': 'test_session',
            'context': {}
        }
        
        logger.info("ğŸ¤– å¼€å§‹æ¨¡æ‹Ÿå¯¹è¯æµç¨‹...")
        logger.info(f"ğŸ“ ç”¨æˆ·æ¶ˆæ¯: {test_input['message']}")
        
        # æ¨¡æ‹Ÿå„æ™ºèƒ½ä½“çš„åˆ†æç»“æœ
        mock_agent_results = {
            'sentiment_agent': {
                'success': True,
                'data': {
                    'sentiment': {
                        'label': 'neutral',
                        'confidence': 0.7
                    }
                }
            },
            'tag_agent': {
                'success': True,
                'data': {
                    'tags': ['inquiry', 'product_interest']
                }
            },
            'knowledge_agent': {
                'success': True,
                'data': {
                    'answer': 'æˆ‘ä»¬æœ‰å¤šç§ä¼˜è´¨äº§å“å¯ä¾›é€‰æ‹©ï¼ŒåŒ…æ‹¬æ•°ç äº§å“ã€å®¶å±…ç”¨å“ç­‰ã€‚'
                }
            },
            'memory_agent': {
                'success': True,
                'data': {
                    'conversation_state': 'product_inquiry',
                    'context': {
                        'user_profile': {
                            'preferred_category': 'electronics'
                        }
                    }
                }
            }
        }
        
        logger.info("ğŸ” æ™ºèƒ½ä½“åˆ†æç»“æœ:")
        for agent, result in mock_agent_results.items():
            if result['success']:
                logger.info(f"  âœ“ {agent}: åˆ†ææˆåŠŸ")
            else:
                logger.warning(f"  âš ï¸ {agent}: åˆ†æå¤±è´¥")
        
        # æ¨¡æ‹Ÿå›å¤ç”Ÿæˆ
        mock_response = "æ‚¨å¥½ï¼æ¬¢è¿å’¨è¯¢æˆ‘ä»¬çš„äº§å“ã€‚æˆ‘ä»¬æä¾›å¤šç§ä¼˜è´¨å•†å“ï¼ŒåŒ…æ‹¬æœ€æ–°çš„æ•°ç äº§å“å’Œç²¾ç¾çš„å®¶å±…ç”¨å“ã€‚æ ¹æ®æ‚¨çš„å…´è¶£ï¼Œæˆ‘æ¨èæ‚¨å…ˆäº†è§£ä¸€ä¸‹æˆ‘ä»¬çš„ç”µå­äº§å“ç³»åˆ—ã€‚æ‚¨æœ‰ç‰¹åˆ«æ„Ÿå…´è¶£çš„äº§å“ç±»å‹å—ï¼Ÿ"
        
        logger.info(f"ğŸ’¬ AIå›å¤: {mock_response}")
        logger.info("âœ… æ¨¡æ‹Ÿå¯¹è¯æµç¨‹å®Œæˆ")
        
        return True
    except Exception as e:
        logger.error(f"âŒ æ¨¡æ‹Ÿå¯¹è¯å¤±è´¥: {e}")
        return False

def test_framework_integration():
    """æµ‹è¯•ä¸‰ä¸ªæ¡†æ¶çš„é›†æˆæƒ…å†µ"""
    logger.info("ğŸ”§ æµ‹è¯•æ¡†æ¶é›†æˆ...")
    
    frameworks = {
        'LangChain': 'åŸºç¡€RAGæ¡†æ¶ï¼Œæä¾›LLMç»Ÿä¸€æ¥å£',
        'Langflow': 'æ™ºèƒ½ä½“å¯è§†åŒ–ç¼–æ’å·¥å…·',
        'RAGFlow': 'ä¸“ä¸šçŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ'
    }
    
    for framework, description in frameworks.items():
        logger.info(f"  ğŸ“‹ {framework}: {description}")
    
    logger.info("ğŸ¯ é›†æˆæ¶æ„:")
    logger.info("  1. RAGFlow -> å¤„ç†çŸ¥è¯†åº“æ£€ç´¢å’Œæ–‡æ¡£è§£æ")
    logger.info("  2. Langflow -> è®¾è®¡å¤šæ™ºèƒ½ä½“å¯¹è¯æµç¨‹")
    logger.info("  3. LangChain -> æä¾›LLMè°ƒç”¨çš„å¤‡ç”¨æ–¹æ¡ˆ")
    
    return True

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ShopTalk-AIåŠŸèƒ½æµ‹è¯•...")
    logger.info("=" * 60)
    
    test_results = []
    
    # 1. æµ‹è¯•æ¨¡å—å¯¼å…¥
    logger.info("ğŸ“¦ æµ‹è¯•1: æ¨¡å—å¯¼å…¥...")
    test_results.append(test_imports())
    
    # 2. æµ‹è¯•é…ç½®åŠ è½½
    logger.info("\nâš™ï¸ æµ‹è¯•2: é…ç½®åŠ è½½...")
    test_results.append(test_config_loading())
    
    # 3. æµ‹è¯•æ™ºèƒ½ä½“åˆ›å»º
    logger.info("\nğŸ¤– æµ‹è¯•3: æ™ºèƒ½ä½“åˆ›å»º...")
    test_results.append(await test_agent_creation())
    
    # 4. æµ‹è¯•æ¨¡æ‹Ÿå¯¹è¯
    logger.info("\nğŸ’¬ æµ‹è¯•4: æ¨¡æ‹Ÿå¯¹è¯æµç¨‹...")
    test_results.append(await test_mock_conversation())
    
    # 5. æµ‹è¯•æ¡†æ¶é›†æˆ
    logger.info("\nğŸ”§ æµ‹è¯•5: æ¡†æ¶é›†æˆè¯´æ˜...")
    test_results.append(test_framework_integration())
    
    # ç»Ÿè®¡ç»“æœ
    logger.info("\n" + "=" * 60)
    passed = sum(test_results)
    total = len(test_results)
    logger.info(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡ ({passed/total*100:.1f}%)")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»ŸåŠŸèƒ½æ­£å¸¸ã€‚")
    else:
        logger.warning(f"âš ï¸ {total-passed}ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")
    
    logger.info("\nğŸ’¡ å…³äºä¸ºä»€ä¹ˆä½¿ç”¨ä¸‰ä¸ªAIæ¡†æ¶:")
    logger.info("1. LangChain: æä¾›æ ‡å‡†åŒ–çš„LLMæ¥å£å’ŒåŸºç¡€RAGåŠŸèƒ½")
    logger.info("2. Langflow: å¯è§†åŒ–è®¾è®¡å¤æ‚çš„å¤šæ™ºèƒ½ä½“å·¥ä½œæµ")
    logger.info("3. RAGFlow: ä¸“ä¸šçš„çŸ¥è¯†åº“ç®¡ç†å’Œæ–‡æ¡£ç†è§£")
    logger.info("è¿™ç§æ¶æ„ç¡®ä¿äº†ç³»ç»Ÿçš„çµæ´»æ€§ã€å¯æ‰©å±•æ€§å’Œä¸“ä¸šæ€§ã€‚")

if __name__ == "__main__":
    asyncio.run(main()) 